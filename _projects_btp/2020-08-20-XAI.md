---
title: "Explainable-AI"
collection: projects_intern
permalink: /projects_intern/2020-08-20-XAI
excerpt: 'Learn a Reinforcement Learning policy that generates saliency maps for the classification made by common classifiers like VGG and ResNet. The RL agent intelligently searches the image for the salient regions to generate the explanantions.'
# date: 2009-10-01
# venue: 'International Conference on Pattern Recognition Applications and Methods 2019, Prague, Czech Republic'
# paperurl: 'http://www.insticc.org/Primoris/Resources/PaperPdf.ashx?idPaper=73925'
# citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
group: "Bachelor Thesis Project"
guide: "Prof Abir Das"
---
<!-- This paper is about the number 1. The number 2 is left for future work. -->

<!-- [Download paper here](http://www.insticc.org/Primoris/Resources/PaperPdf.ashx?idPaper=73925) -->

<!-- Recommended citation: Your Name, You. (2009). "Paper Title Number 1." <i>Journal 1</i>. 1(1). -->

We try to explain the classifications made by common classifiers (VGG, ResNet and EfficientNet) for images from common datasets (PASCAL, MSCOCO and IMAGENET). We treat the models as black-box models so practically any model can be used to generate explanations. The Reinforcement Learning agent is trained to choose regions in the image sequentially in the decreasing order of importance. There are two ways of training the agent. One is the deletion mode where at every step, regions are removed from the image and a decline in the classification score for the target class is observed. Insertion mode of training is opposite to this. Here, regions in images are inserted one by one on an initially blank canvas and an increase in the classification score for the target class is observed.