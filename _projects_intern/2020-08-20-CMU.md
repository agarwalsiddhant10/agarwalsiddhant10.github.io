---
title: "Breaking Backdoored Classifiers"
collection: projects_intern
permalink: /projects_intern/2020-08-20-CMU
excerpt: 'A backdoored classifier cannot be attacked only by the adversary but can be broken by fundamentally anybody. Showed how robustified model of a poisoned classifier reveals its backdoors.'
# date: 2009-10-01
# venue: 'International Conference on Pattern Recognition Applications and Methods 2019, Prague, Czech Republic'
# paperurl: 'http://www.insticc.org/Primoris/Resources/PaperPdf.ashx?idPaper=73925'
# citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
group: "Carnegie Mellon University"
guide: "Prof Zico Kolter"
---
<!-- This paper is about the number 1. The number 2 is left for future work. -->

<!-- [Download paper here](http://www.insticc.org/Primoris/Resources/PaperPdf.ashx?idPaper=73925) -->

<!-- Recommended citation: Your Name, You. (2009). "Paper Title Number 1." <i>Journal 1</i>. 1(1). -->